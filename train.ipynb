{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('src/thwiki.csv')\n",
    "\n",
    "df = df[~df.text.isna()]\n",
    "txt = '\\n'.join(df.text.values)\n",
    "\n",
    "with open('src/thwiki.txt','w') as f:\n",
    "    f.write(txt)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944329"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some text clean up\n",
    "src_file = Path('src/thwiki.txt')\n",
    "lines = src_file.read_text(encoding='utf-8').splitlines()\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690987"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of topic/header text \n",
    "lines = [line for line in lines if ' ' in line]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '\\n'.join(lines)\n",
    "\n",
    "with open('src/thwiki_clean.txt','w') as f:\n",
    "    f.write(txt)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 54s, sys: 43.2 s, total: 8min 37s\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "tokenizer.train(files=['src/thwiki_clean.txt'], vocab_size=20_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ThaiBert/vocab.json', 'ThaiBert/merges.txt']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save(\"ThaiBert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./ThaiBert/vocab.json\",\n",
    "    \"./ThaiBert/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'à¸ªà¸§',\n",
       " 'à¸±',\n",
       " 'à¸ªà¸Ķ',\n",
       " 'à¸µ',\n",
       " 'à¸Ĭà¸²à¸§',\n",
       " 'à¹Ĥà¸¥à¸ģ',\n",
       " 'Ġà¸§',\n",
       " 'à¸±',\n",
       " 'à¸Ļà¸Ļ',\n",
       " 'à¸µà¹ī',\n",
       " 'à¹Ģà¸£à¸²à¸Īà¸°',\n",
       " 'à¸¡à¸²',\n",
       " 'à¹Ģà¸Ĺà¸£',\n",
       " 'à¸Ļ',\n",
       " 'Ġmod',\n",
       " 'el',\n",
       " 'ĠB',\n",
       " 'ER',\n",
       " 'T',\n",
       " 'Ġà¸ģ',\n",
       " 'à¸±',\n",
       " 'à¸Ļà¹Ĥà¸Ķà¸¢à¹ĥà¸Ĭ',\n",
       " 'à¹ī',\n",
       " 'Ġli',\n",
       " 'br',\n",
       " 'ary',\n",
       " 'ĠH',\n",
       " 'ug',\n",
       " 'g',\n",
       " 'ing',\n",
       " 'face',\n",
       " '</s>']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_txt = \"สวัสดีชาวโลก วันนี้เราจะมาเทรน model BERT กันโดยใช้ library Huggingface\"\n",
    "tokenizer.encode(test_txt).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>สวัสดีชาวโลก วันนี้เราจะมาเทรน model BERT กันโดยใช้ library Huggingface</s>'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(test_txt).ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# preparing model config\n",
    "config = {\n",
    "    \"architectures\": [\n",
    "        \"RobertaForMaskedLM\"\n",
    "    ],\n",
    "    \"max_position_embeddings\": 514,\n",
    "    \"vocab_size\": 25_000\n",
    "}\n",
    "with open(\"./ThaiBert/config.json\", 'w') as fp:\n",
    "    json.dump(config, fp)\n",
    "\n",
    "# preparing tokenizer config\n",
    "tokenizer_config = {\n",
    "    \"max_len\": 512\n",
    "}\n",
    "with open(\"./ThaiBert/tokenizer_config.json\", 'w') as fp:\n",
    "    json.dump(tokenizer_config, fp)\n",
    "\n",
    "# preparing train command\n",
    "cmd =\"\"\"\n",
    "#! /bin/bash\n",
    "python run_language_modeling.py\n",
    "--train_data_file ./src/thwiki.txt\n",
    "--output_dir ./ThaiBertModel\n",
    "--model_type roberta\n",
    "--mlm\n",
    "--config_name ./ThaiBert\n",
    "--tokenizer_name ./ThaiBert\n",
    "--do_train\n",
    "--learning_rate 1e-4\n",
    "--pct_warmup 0.3\n",
    "--num_train_epochs 10\n",
    "--save_total_limit 2\n",
    "--save_steps 2000\n",
    "--per_gpu_train_batch_size 16\n",
    "\"\"\".replace(\"\\n\", \" \")\n",
    "\n",
    "with open('./train-model','w') as fp:\n",
    "    fp.write(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    BertTokenizer,\n",
    "    CamembertConfig,\n",
    "    CamembertForMaskedLM,\n",
    "    CamembertTokenizer,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertTokenizer,\n",
    "    GPT2Config,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    OpenAIGPTConfig,\n",
    "    OpenAIGPTLMHeadModel,\n",
    "    OpenAIGPTTokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForMaskedLM,\n",
    "    RobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"gpt2\": (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),\n",
    "    \"openai-gpt\": (OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer),\n",
    "    \"bert\": (BertConfig, BertForMaskedLM, BertTokenizer),\n",
    "    \"roberta\": (RobertaConfig, RobertaForMaskedLM, RobertaTokenizer),\n",
    "    \"distilbert\": (DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer),\n",
    "    \"camembert\": (CamembertConfig, CamembertForMaskedLM, CamembertTokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model & tokenizer class\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[\"roberta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0323 06:42:33.139810 4364248512 configuration_utils.py:277] loading configuration file ./ThaiBert/config.json\n",
      "I0323 06:42:33.141808 4364248512 configuration_utils.py:315] Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 25000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model config from .json file\n",
    "config = config_class.from_pretrained('./ThaiBert', cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0323 06:44:24.790025 4364248512 tokenization_utils.py:420] Model name './ThaiBert' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming './ThaiBert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0323 06:44:24.791359 4364248512 tokenization_utils.py:449] Didn't find file ./ThaiBert/added_tokens.json. We won't load it.\n",
      "I0323 06:44:24.793643 4364248512 tokenization_utils.py:449] Didn't find file ./ThaiBert/special_tokens_map.json. We won't load it.\n",
      "I0323 06:44:24.794605 4364248512 tokenization_utils.py:502] loading file ./ThaiBert/vocab.json\n",
      "I0323 06:44:24.795073 4364248512 tokenization_utils.py:502] loading file ./ThaiBert/merges.txt\n",
      "I0323 06:44:24.795552 4364248512 tokenization_utils.py:502] loading file None\n",
      "I0323 06:44:24.796000 4364248512 tokenization_utils.py:502] loading file None\n",
      "I0323 06:44:24.796465 4364248512 tokenization_utils.py:502] loading file ./ThaiBert/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained('./ThaiBert', cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = tokenizer.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = model_class(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineByLineTextDataset(Dataset):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, file_path: str, block_size=512):\n",
    "        assert os.path.isfile(file_path)\n",
    "        # Here, we do not cache the features, operating under the assumption\n",
    "        # that we will soon use fast multithreaded tokenizers from the\n",
    "        # `tokenizers` repo everywhere =)\n",
    "\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            lines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "        self.examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=block_size)[\"input_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.examples[i], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./src/thwiki.txt\"\n",
    "train_dataset = LineByLineTextDataset(tokenizer, file_path=file_path, block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "def collate(examples: List[torch.Tensor]):\n",
    "    if tokenizer._pad_token is None:\n",
    "        return pad_sequence(examples, batch_first=True)\n",
    "    return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, sampler=train_sampler, batch_size=train_batch_size, collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tokens(inputs: torch.Tensor, tokenizer: PreTrainedTokenizer, mlm_probability) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
    "\n",
    "    if tokenizer.mask_token is None:\n",
    "        raise ValueError(\n",
    "            \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"\n",
    "        )\n",
    "\n",
    "    labels = inputs.clone()\n",
    "    # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    if tokenizer._pad_token is not None:\n",
    "        padding_mask = labels.eq(tokenizer.pad_token_id)\n",
    "        probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    # 10% of the time, we replace masked input tokens with random word\n",
    "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "    inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_probability = .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 251]), torch.Size([8, 251]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = mask_tokens(next(iter(train_dataloader)), tokenizer, mlm_probability)\n",
    "\n",
    "inputs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10.2231, grad_fn=<NllLossBackward>),\n",
       " tensor([[[ 4.0184e-01, -2.7890e-01,  8.7586e-01,  ..., -3.0042e-01,\n",
       "           -2.7622e-01, -7.9671e-01],\n",
       "          [ 4.3925e-01, -1.1127e+00,  6.7683e-01,  ..., -4.5304e-01,\n",
       "            9.4325e-01, -8.7863e-01],\n",
       "          [ 1.0020e+00, -6.9782e-01,  5.9493e-01,  ..., -1.2418e-02,\n",
       "            3.6302e-01, -4.7675e-01],\n",
       "          ...,\n",
       "          [ 3.4202e-01, -5.0038e-01,  7.6054e-01,  ...,  1.0433e-01,\n",
       "            2.2608e-01, -2.1717e-01],\n",
       "          [ 2.7688e-01, -9.8598e-01,  9.2853e-01,  ...,  2.0952e-02,\n",
       "            2.2493e-01,  1.5478e-01],\n",
       "          [-4.5333e-01, -5.9684e-01,  1.0654e+00,  ..., -1.5712e-01,\n",
       "            2.1360e-01, -2.1896e-01]],\n",
       " \n",
       "         [[-2.6811e-01, -4.5348e-01, -1.4080e-02,  ..., -4.0266e-01,\n",
       "           -4.2741e-01, -3.0381e-01],\n",
       "          [ 5.1049e-01,  5.3902e-02,  7.5591e-01,  ..., -1.1826e-01,\n",
       "           -1.5787e-01, -4.0453e-01],\n",
       "          [ 6.3732e-01, -1.3881e+00, -4.5012e-01,  ..., -1.0668e-01,\n",
       "            5.2471e-01, -6.9721e-01],\n",
       "          ...,\n",
       "          [ 4.4579e-01, -2.8399e-01,  6.0536e-01,  ..., -1.0257e-01,\n",
       "            3.3348e-02,  2.5747e-01],\n",
       "          [ 1.8105e-01, -4.6080e-01,  7.2036e-02,  ..., -5.5756e-01,\n",
       "            1.7292e-01, -8.5951e-02],\n",
       "          [-2.0563e-01, -4.6794e-01,  7.3803e-02,  ...,  1.0168e-01,\n",
       "           -3.9156e-01, -1.0024e+00]],\n",
       " \n",
       "         [[ 1.9205e-01, -4.7351e-01,  7.6785e-01,  ..., -7.2497e-01,\n",
       "           -6.2280e-02, -7.6375e-01],\n",
       "          [ 1.6677e-01, -4.0769e-01,  7.7099e-01,  ..., -1.5857e-01,\n",
       "            4.9136e-01, -3.5516e-01],\n",
       "          [ 5.9626e-01, -8.7039e-01,  9.8337e-01,  ...,  3.9933e-01,\n",
       "            1.7312e-01, -6.8878e-01],\n",
       "          ...,\n",
       "          [ 3.7109e-01, -9.2442e-01,  1.2071e+00,  ..., -1.0415e-01,\n",
       "            5.7272e-01, -7.1857e-01],\n",
       "          [-8.1312e-03, -1.1560e+00,  8.9518e-01,  ..., -2.3645e-01,\n",
       "           -2.9606e-02, -3.0241e-02],\n",
       "          [ 2.4386e-01, -1.2963e+00,  8.2416e-01,  ...,  1.4559e-01,\n",
       "            4.8569e-01,  1.6399e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 5.1789e-01, -4.7752e-01,  1.0002e+00,  ..., -1.1229e-01,\n",
       "           -1.8779e-01, -7.0926e-01],\n",
       "          [ 3.7360e-01, -9.9647e-01,  1.1590e+00,  ...,  4.0738e-01,\n",
       "            7.2333e-01, -2.7022e-01],\n",
       "          [ 7.8615e-01, -7.9967e-01,  1.0447e+00,  ..., -3.7545e-01,\n",
       "           -3.2544e-03, -2.4407e-01],\n",
       "          ...,\n",
       "          [ 5.7904e-01, -5.3100e-01,  7.6085e-01,  ..., -4.3298e-01,\n",
       "           -1.0289e-02, -2.6608e-01],\n",
       "          [ 8.2156e-02, -1.0371e+00,  9.5103e-01,  ..., -2.5593e-01,\n",
       "            1.9692e-01, -8.1771e-01],\n",
       "          [ 5.2809e-01, -1.1464e+00,  9.7267e-01,  ..., -1.0310e-01,\n",
       "            1.1569e-03, -3.0754e-01]],\n",
       " \n",
       "         [[ 4.4797e-01, -1.0643e+00,  8.8116e-01,  ..., -2.6759e-01,\n",
       "           -1.1959e-02, -6.7672e-01],\n",
       "          [ 4.5468e-01, -6.0882e-01,  1.0579e+00,  ..., -4.9223e-01,\n",
       "            6.2520e-02, -5.5448e-01],\n",
       "          [ 3.4070e-01, -1.1333e+00,  8.2748e-01,  ...,  1.4812e-02,\n",
       "            3.8180e-01, -5.4014e-01],\n",
       "          ...,\n",
       "          [ 5.4093e-01, -3.9821e-01,  8.3620e-01,  ...,  3.5217e-02,\n",
       "            2.9508e-01, -6.1118e-01],\n",
       "          [-9.9708e-02, -8.1475e-01,  1.5764e+00,  ..., -1.5285e-03,\n",
       "            2.5067e-01,  2.1986e-01],\n",
       "          [ 5.7593e-01, -8.4714e-01,  7.2163e-01,  ...,  1.3284e-01,\n",
       "            2.1332e-01, -7.7527e-01]],\n",
       " \n",
       "         [[ 1.0597e+00, -4.4282e-01,  3.1809e-01,  ..., -3.0470e-01,\n",
       "            5.3589e-02, -8.8694e-01],\n",
       "          [ 2.2773e-01, -7.6506e-01,  6.1169e-01,  ..., -4.5335e-02,\n",
       "           -2.1790e-01, -8.1132e-01],\n",
       "          [ 9.6096e-01, -3.4540e-01,  8.8233e-01,  ...,  2.0026e-01,\n",
       "            5.0917e-01, -4.1002e-01],\n",
       "          ...,\n",
       "          [-2.8383e-01, -8.1564e-01,  1.0590e+00,  ..., -4.3378e-01,\n",
       "           -2.2215e-01,  6.1225e-02],\n",
       "          [ 1.1218e-02, -8.5064e-01,  1.0277e+00,  ...,  2.2863e-02,\n",
       "            3.5290e-01,  8.5566e-02],\n",
       "          [ 5.2147e-01, -7.5497e-01,  7.5511e-01,  ...,  3.7208e-01,\n",
       "            2.6266e-01, -1.4678e-02]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs, masked_lm_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelTrainException(Exception): pass\n",
    "\n",
    "class BertLRFinder:\n",
    "    def __init__(self, model, tokenizer, data_loader, bs, opt, lr_range=[1e-7,1], max_iter=500):\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data_loader = data_loader\n",
    "        self.bs = bs\n",
    "        self.opt = opt\n",
    "        self.lr_range = lr_range\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def run(self):\n",
    "        best_loss = np.inf\n",
    "        i = 0\n",
    "        while i<self.max_iter:\n",
    "            for batch in self.data_loader:\n",
    "                # get masked input and label\n",
    "                inputs, labels = mask_tokens(batch, self.tokenizer, mlm_probability)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # begin batch\n",
    "                pos = i/self.max_iter\n",
    "                i+=1\n",
    "                lr = self.lr_range[0]*(self.lr_range[1]/self.lr_range[0])**pos\n",
    "                for pg in self.opt.param_groups: pg['lr'] = lr\n",
    "                \n",
    "                loss = model(inputs, masked_lm_labels=labels)[0]\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                self.opt.zero_grad()\n",
    "              \n",
    "                # after step\n",
    "                if (loss.item() > best_loss*10) or (i==self.max_iter): raise CancelTrainException()\n",
    "                if loss.item() < best_loss: best_loss = loss.item() \n",
    "\n",
    "                # after batch\n",
    "                self.lrs.append(lr)\n",
    "                self.losses.append(loss.item())\n",
    "        \n",
    "    def plot_lr(self):\n",
    "        # plot lr x loss\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.xscale('log')\n",
    "        \n",
    "    def save_plot(self,dir=Path(\".\"), fig_name=\"lr_x_loss.png\"):\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.xscale('log')\n",
    "        plt.savefig(dir/fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = BertLRFinder(model=model, tokenizer=tokenizer, data_loader=train_dataloader, bs=8, opt=optimizer,\n",
    "                        lr_range=[1e-7,1], max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelTrainException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelTrainException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-5ac256cdd3a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-bd4797a90bfa>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# after step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCancelTrainException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_finder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
